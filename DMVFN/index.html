<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }
    
    h1 {
        font-size:32px;
        font-weight:300;
    }
    
    .disclaimerbox {
        background-color: #eee;     
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }
    
    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }
    
    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
        5px 5px 0 0px #fff, /* The second layer */
        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
        10px 10px 0 0px #fff, /* The third layer */
        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
        15px 15px 0 0px #fff, /* The fourth layer */
        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
        20px 20px 0 0px #fff, /* The fifth layer */
        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
        25px 25px 0 0px #fff, /* The fifth layer */
        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }

    .paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
        5px 5px 0 0px #fff, /* The second layer */
        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
        10px 10px 0 0px #fff, /* The third layer */
        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }
    
    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }
    
    hr
    {
        border: 0;
        height: 1px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
<head>
    <title>DMVFN</title>
    <meta property="og:image" content="resources/teaser.jpg"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
    <meta property="og:title" content="DMVFN" />
    <meta property="og:description" content="DMVFN." />

    <!-- Get from Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src=""></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-81285507-1');
    </script>
</head>

<body>
    <br>
    <center>
        <span style="font-size:36px">A Dynamic Multi-Scale Voxel Flow Network for Video Prediction</span>
        <br>
        <br>

        <table align=center width=1000px>
            <table align=center width=1000px>
                <tr>
                    <td align=center width=200px>
                        <center>
                            <span style="font-size:24px"><a href="https://huxiaotaostasy.github.io" target="_blank">Xiaotao Hu</a></span>
                        </center>
                    </td>
                    <td align=center width=200px>
                        <center>
                            <span style="font-size:24px"><a href="https://github.com/hzwer" target="_blank">Zhewei Huang</a></span>
                        </center>
                    </td>
                    <td align=center width=200px>
                        <center>
                            <span style="font-size:24px"><a href="https://github.com/P2Oileen" target="_blank">Ailin Huang</a></span>
                        </center>
                    </td>
                    <td align=center width=200px>
                      <center>
                          <span style="font-size:24px"><a href="https://csjunxu.github.io/" target="_blank">Jun Xu</a></span>
                      </center>
                  </td>
                  <td align=center width=200px>
                    <center>
                        <span style="font-size:24px"><a href="https://zsc.github.io/" target="_blank">Shuchang Zhou</a></span>
                    </center>
                </td>
                </tr>
            </table>
            <table align=center width=500px>
                <tr>
                    <td align=center width=160px>
                        <center>
                            <span style="font-size:24px"><a target="_blank" href='https://arxiv.org/abs/2303.09875'>[Paper]</a></span>
                        </center>
                    </td>
                    <td align=center width=160px>
                        <center>
                            <span style="font-size:24px"><a target="_blank" href='https://github.com/megvii-research/CVPR2023-DMVFN'>[Pytorch]</a></span><br>
                        </center>
                    </td>
                    <td align=center width=160px>
                      <center>
                          <span style="font-size:24px"><a target="_blank" href='https://github.com/MegEngine/MegEngine-DMVFN'>[MegEngine]</a></span><br>
                      </center>
                  </td>
                </tr>
            </table>
        </table>
    </center>

    <center>
        <br>
        <table align=center width=850px>
            <tr>
                <td width=260px>
                    <center>
                        <video controls autoplay loop muted width='800px'>
                          <source src="./resources/kitti.mp4" type="video/mp4"/>
                        </video>
                    </center>
                </td>
            </tr>
        </table>
    </center>
    <br>

    <hr>

    <table align=center width=850px>
        <center><h1>Abstract</h1></center>
        <tr>
            <td>
              <p>The performance of video prediction has been greatly boosted by advanced deep neural networks. However, most of the current methods suffer from large model sizes and require extra inputs, eg, semantic/depth maps, for promising performance.For efficiency consideration, in this paper, we propose a Dynamic Multi-scale Voxel Flow Network (DMVFN) to achieve better video prediction performance at lower computational costs with only RGB images, than previous methods. The core of our DMVFN is a differentiable routing module that can effectively perceive the motion scales of video frames. Once trained, our DMVFN selects adaptive sub-networks for different inputs at the inference stage. Experiments on several benchmarks demonstrate that our DMVFN is an order of magnitude faster than <a href="https://github.com/liuziwei7/voxel-flow">Deep Voxel Flow</a> and surpasses the state-of-the-art iterative-based <a href="https://github.com/YueWuHKUST/CVPR2022-Optimizing-Video-Prediction-via-Video-Frame-Interpolation">OPT</a> on generated image quality.</p>
            </td>
        </tr>
    </table>
    <br>

    <hr>
    <center><h1>Experiments</h1></center>
<!--    <p>要展示的图片：</p>-->
            <table align=center width=850px>
            <tr>
<!--                <td width=260px>-->
                <center>
                        <img src="resources/fig1.png" width="362" height="292">


            <img src="resources/comparison.png" width="294" height="298">
                    </center>
            </tr>
        </table>
    <table align=center>
      <tr>
        <td>
          <p>DMVFN outperforms previous methods in terms of image quality, parameter amount, and GFLOPs.</p>
        </td>
      </tr>
    </table>
    <br>

    <hr>

    <center><h1>Ablations</h1></center>

    <table align=center width=850px>
            <tr>
                <center>
                <img src="resources/abl.png" width="831" height="195">
                </center>
            </tr>
        </table>

    <table align=center width=850px>
      <tr>
        <td>
          <p>(a): Average usage rate on videos with different motion magnitudes. "Fast": tested on Vimeo-Fast. "Medium": tested on Vimeo-Medium. "Slow": tested on Vimeo-Slow. (b): Difference between "Fast"/"Slow" and "Medium" of (a). (c): Averaged usage rate on different time intervals between two input frames from Vimeo-Slow. "Int.": time interval.</p>
          </td>
      </tr>
    </table>
    <br>




    <hr>
    <table align=center width=800px>
        <center><h1>Paper and Supplementary Material</h1></center>
        <center><p>For more details and experiments check out our paper:</p></center>
        <tr>
            <td><a target="_blank" href=''><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
            <td><span style="font-size:14pt">Xiaotao Hu, Zhewei Huang, Ailing Huang, Jun Xu, Shuchang Zhou.<br>
                A Dynamic Multi-Scale Voxel Flow Network for Video Prediction.<br>
                CVPR 2023.<br>
                (hosted on <a target="_blank" href="">ArXiv</a>)<br>
                <br>
                <a href="./resources/bibtex.txt" target="_blank">[Bibtex]</a>
                </span>
            </td>

        </tr>
    </table>
    <br>

    <br>

    <hr>
    <br>

    <table align=center width=900px>
        <tr>
            <td width=400px>
                <center>
                    This <a href="https://github.com/richzhang/webpage-template">template</a> was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a>.
                </center>
            </td>
        </tr>
    </table>

<br>
</body>
</html>






